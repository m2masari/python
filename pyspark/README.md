## Pyspark Projects and descriptions

## Author: Melik Masarifoglu

**file name: pyspark_datamanip_logistic**<br/>  
The file contains data manipulation techniques and how to apply logistic regression model<br/>  
* Join<br/>
* Case when<br/> 
* Distinct<br/>
* Rename columns<br/>
* How to find min,max,avg,sum,count,standard deviation<br/> 
* Order by-sort
* Group by sum,count,mean<br/> 
* Filter<br/> 
* Rank<br/> 
* An example of Machine Learning methods of logistic regression (how to create feutures labels,and ROC value)<br/><br/> 

**file name: pyspark_null_values**<br/>
This file talks about how to manage missing values in pyspark and try to answer below questions: <br/> 
  
* check each row and filter the ones without any null value<br/>
* Filter the rows that has at least n null values.<br/>
* Filter the null values/non-values in a specific column<br/> 
* Replace null values with numeric value (if the column is numeric)<br/>
* Replace null values with string value  (if the column is string)<br/>
* How to replace null values either with mean or median<br/>
* What impacts can null values have on calculating average and count<br/> 

**file name: machine_learning_technique**<br/>
* Model Lojistic regression on train data set 
* Corelation graph of predictor variables
* Roc curve and area under the roc curve
* Test the model on the test data set 
* Report prediction, sensitivity, positive probability, negative probability
* Precision, accuracy, sensitivity

**file name: RDD_word_count**<br/>
* Read the text in RDD format
* Remove all punctuation marks
* Change all capital letters to lower case letters
* Split the text
* Remove unwanted words
* Map the text 
* ReduceByKey
* Sort the words and list the most occured top 5 word 

**file name: Pyarrow_toPandas**<br/>
* How to install PyArrow module to eliminate time consumption between pyspark dataframe to pandas dataframe 
* How pyarrow performs and lowers the time
